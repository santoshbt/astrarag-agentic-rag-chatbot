# LLM configuration mapping agent names to LLMs
LLM_CONFIG = {
    "Question Answer Agent": {
        "model": "groq/llama-3.3-70b-versatile",
        "temperature": 0.0,
    }
}
